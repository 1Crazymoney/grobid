<?xml version="1.0" ?>
<tei>
	<teiHeader>
		<fileDesc xml:id="Wang-paperAVE2008"/>
	</teiHeader>
	<text xml:lang="en">
		<front>
<lb/>
	<docTitle>
	<titlePart>Information Synthesis for Answer Validation<lb/></titlePart>
	</docTitle>

	<byline>
	<docAuthor>Rui Wang 1 and Günter Neumann 2<lb/></docAuthor>
	</byline>

	<byline>
	<affiliation>1 Saarland University<lb/></affiliation>
	</byline>

	<address>66123 Saarbrücken, Germany<lb/></address>

	<email>rwang@coli.uni-sb.de<lb/></email>

	<byline>
	<affiliation>2 LT-Lab, DFKI<lb/></affiliation>
	</byline>

	<address>Stuhlsatzenhausweg 3, 66123 Saarbrücken, Germany<lb/></address>

	<email>neumann@dfki.de<lb/></email>

	<div type="abstract">Abstract. This report is about our participation in the Answer Validation Exercise (AVE2008).<lb/> Our system casts the AVE task into a Recognizing Textual Entailment (RTE) problem and uses an<lb/> existing RTE system to validate answers. Additional information from named-entity (NE)<lb/> recognizer, question analysis component, and so on, is also considered as assistances to make the<lb/> final decision. In all, we have submitted two runs, one run for English and the other for German.<lb/> They have achieved f-measures of 0.64 and 0.61 respectively. Compared with our system last year,<lb/> which purely depends on the output of the RTE system, the extra information does show its<lb/> effectiveness.<lb/></div>

	<keyword>Keywords: Answer Validation, Recognizing Textual Entailment, Information Synthesis<lb/></keyword>

	<div type="abstract">1 Introduction and Related Work<lb/> Answer Validation is an important step for Question Answering (QA) systems, which aims to validate the<lb/> answers extracted from natural language texts, and select the most proper answers for the final output.<lb/> Using Recognizing Textual Entailment (RTE-1 – Dagan et al., 2006; RTE-2 – Bar-Haim et al., 2006) to do<lb/> answer validation has shown a great success (Peñas et al., 2007). We also developed our own RTE system and<lb/> participated in AVE2007. The RTE system proposed a new sentence representation extracted from the<lb/> dependency structure, and utilized the Subsequence Kernel method (Bunescu and Mooney, 2006) to perform<lb/> machine learning. We have achieved fairly high results on both the RTE-2 data set (Wang and Neumann, 2007a)<lb/> and the RTE-3 data set (Wang and Neumann, 2007b), especially on Information Extraction (IE) and QA pairs.<lb/> However, on the AVE data sets, we still found much space for the improvement. Therefore, based on the<lb/> system we developed last year, our motivation this year is to see whether using extra information, e.g. named-<lb/>entity (NE) recognition, question analysis, etc., can make further improvement on the final results.<lb/> This report will start with a brief introduction of our RTE system and then followed by the whole AVE<lb/> system. The results of our two submission runs will be shown in section 4, and in the end, we will summarize<lb/> our work.<lb/></div>

		</front>
	</text>
</tei>
