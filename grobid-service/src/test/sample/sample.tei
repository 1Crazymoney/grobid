<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" xmlns:xlink="http://www.w3.org/1999/xlink" 
 xmlns:mml="http://www.w3.org/1998/Math/MathML">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a">Bi-criteria Algorithm for Scheduling Jobs on Cluster Platforms</title>
			</titleStmt>
			<publicationStmt>
				<date>20 Jan 2005</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<title level="a" type="main">Bi-criteria Algorithm for Scheduling Jobs on Cluster Platforms</title>
						<author>
							<persName>
								<forename>Pierre-Francois</forename>
								<surname>Dutot</surname>
							</persName>
							<affiliation>
								<orgName type="laboratory">ID-IMAG</orgName>
								<orgName type="team">Informatique et Distribution</orgName>
								<country>FR</country>
								<address><addrLine>ENSIMAG - antenne de Montbonnot ZIRST - 51, avenue Jean Kuntzmann - 38 330 Montbonnot Saint Martin</addrLine></address>
								<orgName type="institution">CNRS : UMR5132</orgName>
								<orgName type="institution">INRIA</orgName>
								<orgName type="institution">Institut National Polytechnique de Grenoble - INPG</orgName>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename>Lionel</forename>
								<surname>Eyraud-Dubois</surname>
							</persName>
							<affiliation>
								<orgName type="laboratory">ID-IMAG</orgName>
								<orgName type="team">Informatique et Distribution</orgName>
								<country>FR</country>
								<address><addrLine>ENSIMAG - antenne de Montbonnot ZIRST - 51, avenue Jean Kuntzmann - 38 330 Montbonnot Saint Martin</addrLine></address>
								<orgName type="institution">CNRS : UMR5132</orgName>
								<orgName type="institution">INRIA</orgName>
								<orgName type="institution">Institut National Polytechnique de Grenoble - INPG</orgName>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename>Gr&#233;gory</forename>
								<surname>Mouni&#233;</surname>
							</persName>
							<affiliation>
								<orgName type="laboratory">ID-IMAG</orgName>
								<orgName type="team">Informatique et Distribution</orgName>
								<country>FR</country>
								<address><addrLine>ENSIMAG - antenne de Montbonnot ZIRST - 51, avenue Jean Kuntzmann - 38 330 Montbonnot Saint Martin</addrLine></address>
								<orgName type="institution">CNRS : UMR5132</orgName>
								<orgName type="institution">INRIA</orgName>
								<orgName type="institution">Institut National Polytechnique de Grenoble - INPG</orgName>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename>Denis</forename>
								<surname>Trystram</surname>
							</persName>
							<affiliation>
								<orgName type="laboratory">ID-IMAG</orgName>
								<orgName type="team">Informatique et Distribution</orgName>
								<country>FR</country>
								<address><addrLine>ENSIMAG - antenne de Montbonnot ZIRST - 51, avenue Jean Kuntzmann - 38 330 Montbonnot Saint Martin</addrLine></address>
								<orgName type="institution">CNRS : UMR5132</orgName>
								<orgName type="institution">INRIA</orgName>
								<orgName type="institution">Institut National Polytechnique de Grenoble - INPG</orgName>
							</affiliation>
						</author>
					</analytic>
					<note>* Authors are members of the APACHE project supported by CNRS , INPG , INRIA , UJF Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page . To copy otherwise , to republish , to post on servers or to redistribute to lists , requires prior specific permission and/or a fee . SPAA&apos;04 , June 27&#8211;30 ,</note>
					<keywords type="subject-headers">Categories and Subject Descriptors F.2.2 [ Analysis of Algorithms and Problem Complex- ity ]: Nonnumerical Algorithms and Problems—Sequencing and scheduling ; D.4.1 [ Operating Systems ]: Process man- agement—Scheduling, Concurrency General Terms Algorithms, Management</keywords>
					<keywords>Parallel Computing, Algorithms, Scheduling, Parallel Tasks, Moldable Tasks, Bi-criteria</keywords>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
	</teiHeader>
	<text xml:lang="en">
		<front>
			<div type="abstract">
				<head>ABSTRACT</head>
<p>We describe in this paper a new method for building an efficient algorithm for scheduling jobs in a cluster. Jobs are considered as parallel tasks (PT) which can be scheduled on any number of processors. The main feature is to consider two criteria that are optimized together. These criteria are the makespan and the weighted minimal average completion time (minsum). They are chosen for their complementarity, to be able to represent both user-oriented objectives and system administrator objectives. We propose an algorithm based on a batch policy with increasing batch sizes, with a smart selection of jobs in each batch. This algorithm is assessed by intensive simulation results, compared to a new lower bound (obtained by a relaxation of ILP) of the optimal schedules for both criteria separately. It is currently implemented in an actual real-size cluster platform.</p>
			</div>
		</front>
		<body>
			<div n="1">
				<head>INTRODUCTION</head>
			</div>
			<div n="1.1">
				<head>Cluster computing</head>
<p>The last few years have been characterized by huge technological changes in the area of parallel and distributed computing. Today, powerful machines are available at low price everywhere in the world. The main visible line of such changes is the large spreading of clusters which consist in a collection of tens or hundreds of standard almost identical processors connected together by a high speed interconnection network <ref type="bibr" target="B5">[6]</ref>. The next natural step is the extension to local sets of clusters or to geographically distant grids <ref type="bibr" target="B9">[10]</ref>. In the last issue of the Top500 ranking (from November 2003 <ref type="bibr" target="B0">[1]</ref>), 52 networks of workstations (NOW) of different kinds were listed and 123 entries are clusters sold either by IBM, HP or Dell. Looking at previous rankings we can see that this number (within the Top500) approximately doubled each year. This democratization of clusters calls for new practical administration tools. Even if more and more applications are running on such systems, there is no consensus towards an universal way of managing efficiently the computing resources . Current available scheduling algorithms were mainly created to provide schedules with performance guaranties for the makespan criterion (maximum execution time of the last job), however most of them are pseudo-polynomial, therefore the time needed to run these algorithms on real instances and the difficulty of their implementation is a drawback for a more popular use. We present in this paper a new method for scheduling the jobs submitted to a cluster inspired by several existing theoretically well-founded algorithms. This method has been assessed on simulations and it is currently tested on actual conditions of use on a large cluster composed by 104 bi-processor machines from Compaq (this cluster &#8211; called Icluster2 &#8211; was ranked 151 in the Top500 in June 2003).</p>
<p>To achieve reasonable performance within reasonable time, we decided to build a fast algorithm which has the best features of existing ones. However, to speed up the algorithm a guaranteed performance ratio cannot be achieved, thus we concentrate on the average ratio on a large set of generated test instances. These instances are representative of jobs submitted on the Icluster <ref type="bibr" target="B17">[18]</ref>.</p>
			</div>
			<div n="1.2">
				<head>Related approaches</head>
<p>Some scheduling algorithms have been developed for classical parallel and distributed systems of the last generations . Clusters introduce new characteristics that are not really taken into account into existing scheduling modules, namely, unbalance between communications and computations &#8211; communications are relatively large &#8211; or on-line submissions of jobs. Let us present briefly some schedulers used in actual systems: the basic idea in job schedulers <ref type="bibr" target="B12">[13]</ref> is to queue jobs and to schedule them one after the other using some simple rules like FCFS (First Come First Served) with priorities. MAUI scheduler <ref type="bibr" target="B13">[14]</ref> extends the model with additional features like fairness and backfilling. AppleS is an application level scheduler system for grid. It is used to schedule, for example, an application composed of a large set of independent jobs with shared data input files <ref type="bibr" target="B3">[4]</ref>. It selects resources efficiently and takes into account data distribution time. It is designed for grid environment. There exist other parallel environments with a more general spectrum (heterogeneous and versatile execution platform ) like Condor <ref type="bibr" target="B15">[16]</ref> or with special capabilities like processus migration, requiring system-level implementation like Mosix <ref type="bibr" target="B2">[3]</ref>. However, in these environments scheduling algorithms are online algorithms with simple rules.</p>
			</div>
			<div n="1.3">
				<head>Our approach</head>
<p>As no fast and flexible scheduling systems are available today for clusters, we started two years ago to develop a new system based on a sound theoretical background and a significant practical experience of managing a big cluster (Icluster1, a 225 PC machine arrived in 2001 in our lab). It is based on the model of parallel tasks <ref type="bibr" target="B8">[9]</ref> which are independent jobs submitted by the users. We are interested here in optimizing simultaneously two criteria, namely the minsum (&#931;Ci) which is usually targeted by the users who all want to finish their jobs as soon as possible , and the makespan (Cmax) which is rather a system administrator objective representing the total occupation time of the platform. There exist algorithms for each criterion separately; we propose here a bi-criteria algorithm to optimize the Cmax and &#931;Ci criteria simultaneously. The best existing algorithm for minimizing the makespan off-line (all jobs are available at the beginning) has a 3/2 + &#491; guaranty <ref type="bibr" target="B6">[7]</ref>. We can derive easily an on-line batch version by using the general framework of <ref type="bibr" target="B20">[21]</ref> leading to an approximation ratio of 3 + &#491;. For the other criterion, the best result is 8 for the unweighted case and 8.53 for the weighted case <ref type="bibr" target="B18">[19]</ref>. Using a nice generic framework introduced by Hall et al.<ref type="bibr" target="B11">[12]</ref>, a (12;12) approximation can be obtained at the cost of a big complexity which impedes the use of such algorithms. The paper is organized as follows: In the next section, we will introduce the definitions and models used in all the paper. The algorithm itself is described in section 3, along with the lower bound which is used in the experiments. The experimental setting and the results are discussed in section 4. Finally we will conclude in section 5 with a discussion on on-going works.</p>
			</div>
			<div n="2">
				<head>CONTEXT AND DEFINITION</head>
			</div>
			<div n="2.1">
				<head>Architectural and Computing Models</head>
<p>The target execution support that we consider here is a cluster composed by a collection of a medium number of SMP or simple PC machines (typically several dozens or several hundreds of nodes). The nodes are fully connected and homogeneous.</p>
			<figure>
				<head>Figure 1</head>
				<figDesc>Job submission in clusters</figDesc>
			</figure>
<p>The submissions of jobs is done by some specific nodes by the way of several priority queues as depicted in Figure 1. No other submission is allowed. Informally, a Parallel Task (PT) is a task that gathers elementary operations, typically a numerical routine or a nested loop, which contains itself enough parallelism to be executed by more than one processor. We studied scheduling of one specific kind of PT, denoted as moldable jobs according to the classification of Feitelson et al. <ref type="bibr" target="B7">[8]</ref>. The number of processors to execute a moldable job is not fixed but determined before the execution, as opposed to rigid jobs where the number of processors is fixed by the user at submission time. In any case, the number of processors does not change until the completion of the job. For historical reasons, most of submitted jobs are rigid. However, intrinsically, most parallel applications are moldable . An application developer does not know in advance the exact number of processors which will be used at run time. Moreover, this number may vary with the input problem size or number of available nodes. This is also true for many numerical parallel libraries. The main exception to this rule is when a minimum number of processors is required because of time, memory or storage constraints. The main restriction in a systematic use of the moldable character is the need for a practical and reliable way to estimate (at least roughly) the parallel execution time as function of the number of processors. Most of the time, the user has this knowledge but does not provide it to the scheduler, as it is not taken into account by rigid jobs schedulers. This is an inertia factor against the more systematic use of such models, as the users habits have to be changed.</p>
<p>Our algorithm proposes, thanks to moldability, to efficiently decrease average response time (at the users request) while keeping computing overhead and idle time as low as possible (at the system administrators request).</p>
			</div>
			<div n="2.2">
				<head>Scheduling on clusters</head>
<p>The main objective function used historically is the makespan. This function measures the ending time of the schedule, i.e., the latest completion time over all the tasks. However, this criterion is valid only if we consider the tasks altogether and from the viewpoint of a single user. If the tasks have been submitted by several users, other criteria can be considered. Let us present briefly the two criteria:</p>
				<list type="inline">
					<item>Minimization of the makespan (Cmax = max(Cj) where the completion time Cj is equal to &#963;(j)+pj(nbproc(j))). pj represents the execution time of task j, &#963; function is the starting time and nbproc function is the processor number (it can be a vector in the case of specific allocations for heterogeneous processors).</item>
					<item>Minimization of the average completion time (&#931;Ci) <ref type="bibr" target="B19">[20]</ref> <ref type="bibr" target="B1">[2]</ref> and its variant weighted completion time (&#931;&#969;iCi). Such a weight may allow us to distinguish some tasks from each other (priority for the smallest ones, etc.).</item>
				</list>
<p>In a production cluster context, the jobs are submitted at any time. Models were the characteristics of the tasks (duration, release date, etc) are only known when the task is submitted are called on-line as opposed to the off-line models were all the tasks are known and available at all times. It is possible to schedule jobs on-line with a constant competitive ratio for Cmax. The idea is to schedule jobs by batches depending on their arrival time. An arriving job is scheduled in the next starting batch. This simple rule allows constant competitive ratio in the on-line case if a single batch may be scheduled with a constant competitive ratio &#961;. Roughly, the last batch starts after the last task arrival date. By definition, all the tasks scheduled in a batch are scheduled in less than &#961;C * max , where C * max is the optimal offline makespan of the complete instance. The length of the previous last batch is then lower than &#961;C * max . Moreover, the length of the last batch, plus the starting time of the previous last batch (at which none of the tasks of the last batch were released) is less than &#961; times the length of the optimal on-line makespan. As the on-line makespan is larger than the off-line makespan, the total schedule length is less than 2&#961; times the on-line optimal makespan. This is how the off-line 3/2 + &#491; algorithm is turned into an on-line 3 + &#491; algorithm as we said in the introduction.</p>
			</div>
			<div n="3">
				<head>A NEW BICRITERIA EFFICIENT SOLUTION</head>
			</div>
			<div n="3.1">
				<head>Rationale</head>
<p>Studying some extreme instances and their optimal schedules for the minsum criterion, gave us an insight on the shape of the schedules we had to build. For example, if all the tasks are perfectly moldable (when the work does not depend on the number of processors) the optimal solution is to schedule all the tasks on all processors in order of increasing area.</p>
<p>This example shows that the minsum criterion tends to give more importance to the smaller tasks. Previous algorithms presented in the literature are also designed to take into account this global structure of scheduling the smaller tasks first. Shmoys et al. <ref type="bibr" target="B11">[12]</ref> used a batch scheduling with batches of increasing sizes. The batch length is doubled at each step, therefore only the smaller tasks are scheduled in the first batches. Existing makespan algorithms for moldable tasks are also designed with a common structure of shelves (were all tasks start at the same time) which is a relaxed version of batches. See for example <ref type="bibr" target="B16">[17]</ref> or <ref type="bibr" target="B6">[7]</ref> for schedules with 2 shelves. Our algorithm was built with this structure in mind: stacking tasks in shelves of increasing sizes with the additional possibility of shuffling these shelves if necessary. However, our main motivation was to design a fast algorithm for the management of some clusters of a big regional grid in Grenoble . Our algorithm does not have a known performance guaranty on the worst cases, however we tested its behavior on a set of generated instances which simulate real jobs submitted on our local clusters. The principle of the algorithm is shown in Figure 2.</p>
			<figure>
				<head>Figure 2</head>
				<figDesc>Principle of the algorithm</figDesc>
			</figure>
<p>end for T = {1..n} for j = 0..K do S = {i &#8712; T such that &#8707;j, pi(j) &#8804; tj} Merge the small sequential tasks sorted by decreasing weight. Select the set Sj &#8838; S of tasks to schedule in the current batch (using a knapsack). Schedule the batch between tj and tj+1. Remove Sj from T . end for Compact the schedule with a list algorithm using the batch ordering.</p>
<p>First, our algorithm calls a dual approximation makespan algorithm (defined in <ref type="bibr" target="B6">[7]</ref>) to determine an approximation of the optimal makespan of the instance. With this value C * max and the smallest possible duration of a task tmin, we compute the smallest useful batch size t0 (such that at least one task can be done) and K + 1 the number of batches. The values tj are the length of our batches. For every j, tj+1 is twice the value of tj. The main loop of the algorithm corresponds to the selection of the jobs to be scheduled in the current batch. We first select the tasks which are not too long to run in the batch. If there are several tasks that can be run in less than half the batch size on one processor, we can merge some of these tasks by stacking them together. In order to have as much weight as possible, this merge is done by decreasing weight order. The next step is to run a knapsack selection, written with integer dynamic programming. We want to maximize the sum of the weight of the selected tasks while using at most m processors. The allocation of the task i is alloti, the smallest allocation that fits (in length) into the batch. Values of W (i, j) are initialized to &#8722;&#8734; for j &lt; 0 and 0 otherwise. For i going from 1 to n and for j going from 1 to m, we compute:</p>
<p>W (i, j) = max (W (i &#8722; 1, j), W (i &#8722; 1, j &#8722; alloti) + wi)</p>
<p>The largest W (n, &#183;) is the maximum weight that can be done in the batch. The complexity of this knapsack is O(mn). The first schedule is simple: we start all the selected tasks of one batch at the same time. A straightforward improvement is to start a task at an earlier time if all the processors it uses are idle. A further improvement is to use a list algorithm with the batch ordering and a local ordering within the batches, as it allows to change the set of processors alloted to the tasks. Finally, an additional optimization step is used. The batch order is shuffled several times and the best resulting compact schedule is kept. This only leads to small improve- ments. The overall complexity of this algorithm is O(mnK).</p>
			</div>
			<div n="3.3">
				<head>Lower Bound</head>
<p>In order to assess this algorithm with experiments, for each instance we need to know the value of an optimal solution . But since the problem is NP-Hard in the strong sense, computing an optimal solution in reasonable time is impossible . We are thus looking for good lower bounds. For Cmax a good lower bound may easily be obtained by dual approximation <ref type="bibr" target="B6">[7]</ref>. For &#931;Ci the lower bound is computed by a relaxation of a Linear Programming formulation of the problem. This formulation is not intended to yield a feasible schedule, but rather to express constraints that are necessarily respected by every feasible schedule. For this formulation, we divided the time horizon into several intervals Ij = (tj, tj+1] with 0 &#8804; j &#8804; K. The values of the tj and the value of K are defined as in the previous section. Once the time division is fixed, we consider the decision variables xi,j = 1 if and only if task i ends within Ij (i.e. between tj and tj+1), and xi,j = 0 otherwise. For each task i and each interval j, we can also compute the minimal area occupied by task i if it ends before tj+1:</p>
<p>Si,j = min</p>
<p>1&#8804;k&#8804;m</p>
<p>{kpi(k) such that pi(k) &#8804; tj+1}</p>
<p>If the set is empty, let Si,j = +&#8734;.</p>
<p>With these values, we can give the formulation of the problem:</p>
<p>Minimize i,j witj xi,j Subject to &#8704;i, j xi,j &#8805; 1 &#8704;j,</p>
<p>0&#8804;l&#8804;j</p>
<p>The first constraint expresses that every task should be performed at least once. The minimization criterion implies that no task will be performed more than once: if xi,j and x i,j &#8242; are equal to one, we get a better, yet still feasible solution by setting one of them to zero. The second constraint is a surface argument. For each interval Ij, we consider the tasks that end before or in this interval (they end in I l , for l &#8804; j). By definition, a task i ending in interval l takes up a surface at least S i,l . The sum of all these surfaces has to be smaller than the total surface between time 0 and time tj+1, which is mtj+1. This is obviously optimistic, because it does not take into account collisions between tasks: scheduling according to this formulation might require more than m processors. Both of these constraints are satisfied by every feasible schedules, so for every feasible schedule S, there is a solution R to this linear program. Since for each job i, j tjxi,j &#8804; Ci, the objective function of R is not larger than the minsum criterion of the schedule S. In particular, every optimal schedule yields a solution to the linear program, so the optimal value of the objective function is always smaller than the optimal value of the minsum criterion of the scheduling problem. This still holds when considering the relaxed problem, where xi,j is in [0; 1]. The lower bound might be weaker, but is much faster to compute.</p>
			</div>
			<div n="4">
				<head>EXPERIMENTS</head>
			</div>
			<div n="4.1">
				<head>Experimental setting</head>
<p>The experimental simulations presented here were performed with an ad-hoc program. Each experience is obtained by 40 runs; for each run tasks are generated in an off-line manner, then given as an input to the scheduling algorithm and to the linear solver which computes a lower bound for this instance. Comparison between the two results yields a performance ratio, and the average ratio for the whole set of runs is the result of the experiments. The runs were made assuming a cluster of 200 processors, and a number of tasks varying from 25 to 400. In order to describe a mono-processor task, only its computing time is needed. A moldable task is described by a vector of m processing times (one per number of processor alloted to the task). We used two different models to generate the tasks. The first one generates the sequential processing times of the tasks, and the second one uses a parallelism model to derive all the other values. Two different sequential workload type were used: uniform and mixed cases. For all uniform cases, sequential times were generated according to an uniform distribution, varying from 1 to 10. For mixed cases, we introduce two classes : small and large tasks. The random values are taken with gaussian distributions centered respectively on 1 and 10, with respective standard deviations of 0.5 and 5, the ratio of small tasks being 70%.</p>
<p>Modeling the parallelism of the jobs was done in two different ways. In the first, successive processing times were computed with the formula pi(j) = pi(j &#8722; 1) X+j</p>
<p>Gang : Each task is scheduled on all processors. The tasks are sorted using the ratio of the weight over the execution time. This algorithm is optimal for instances with linear speedup.</p>
<p>Sequential : Each tasks is scheduled on a single processor. A list algorithm is used, scheduling large processing time first (LPTF).</p>
<p>List Graham: All the 3 algorithms are multiprocessor list scheduling <ref type="bibr" target="B10">[11]</ref>. Every tasks is alloted using the number of processor selected by <ref type="bibr" target="B6">[7]</ref>. This should lead to a very good average performance ratio with respect to the Cmax criterion. Only the order of the list is changing between the three algorithms :</p>
				<list type="inline">
					<item>the first one keep the order of <ref type="bibr" target="B6">[7]</ref>, listing first task of the large shelf then the tasks of small shelf then the small tasks,</item>
					<item>weighted largest processing time first (LPTF), a classical variant, with a very god behavior for Cmax criterion, but the tasks are in fact sorted using the ratio between weighted and their execution time.</item>
					<item>smallest area first (SAF), almost the opposite of LPTF, the tasks are sorted according to their area (number of processors &#215; execution time). The goal is to improve the average performance ratio for the wiCi criterion.</item>
				</list>
<p>In all experiments, task priority is a random value taken from an uniform distribution between 1 and 10.</p>
			</div>
			<div n="4.2">
				<head>Simulation results</head>
<p>The results of the simulation runs are given in all the following figures, plotting the minimum, maximum and average values for Cmax and wiCi. The average of the competitive ratio is computed by dividing the sum of the execution times over the sum of the lower bounds for every point</p>
<p><ref type="bibr" target="B14">[15]</ref>. Every workload type are represented separately. The same scale is represented for identical criterion between the workload type. The tasks of Figure 3 are weakly parallel. This is the worst case for our algorithm as it spends resources to accelerate completion of small and high priority parallel tasks. These resources are thus spend without much gain. Note that Gang scheduling does not appear in the presented range for Cmax, as Gang always has a very big ratio in this case. As expected, the average performance ratio for our algorithm is worse than all other algorithms except Gang. Nevertheless , the performance ratio for Cmax is no more than 2. All other algorithms have an average performance ratio around 1.5. The difference is large enough to influence also the results for the minsum criterion. From this case we may deduce that for most cases, our algorithms will not be much worse than a performance ratio of 2 for both criterion.</p>
<p>0 50 100 150 200 250 300 350 400 450</p>
<p>Number of tasks</p>
<p>Weakly Parallel</p>
<p>Sequential</p>
<p>List Scheduling</p>
<p>Figure 4 presents the same experiments with the highly parallel tasks. On the minsum criterion, our algorithm is clearly the best one. Gang and sequential have opposite behavior on both criteria, Gang being good with a small number of tasks and sequential good for a large number of tasks only. The other algorithms are stable (with respect to</p>
<p>0 50 100 150 200 250 300 350 400 450</p>
<p>Number of tasks</p>
<p>Higly Parallel</p>
<p>Sequential</p>
<p>List Scheduling</p>
			<figure>
				<head>Figure 4</head>
				<figDesc>Performance ratio for the simulation on 200 processors, highly parallel tasks</figDesc>
			</figure>
<p>Sequential</p>
<p>List Scheduling</p>
<p>the number of tasks) but with a larger ratio on the minsum. Remark that the allotment computed for list algorithms is quite good, as Cmax performance ratio of these algorithms is always smaller than 2. The next experiment (cf Figure 5) presents mixed instances with some large tasks and plenty of small tasks. In this cases our algorithm is still quite stable with a performance ratio of around 2 for both criterion, however SAF is better than our algorithm. The ratio of the two other list algorithms greatly increase with the number of tasks, which points out that the order of tasks is very important here. Finally, the last experiment use a well known workload generator which emulates real applications <ref type="bibr" target="B4">[5]</ref>. In this more realistic setting our algorithm clearly outperforms the other ones for the minsum criterion, and is also the only one to keep a stable ratio for any number of tasks. Several observations can be made from these results. First, the performance ratio for the minsum criterion is never more than 2.5, and is on average around 2. The performance ratio for the makespan is almost always below 2, and is 1.9 on average . This is very good, even for each criterion separately.</p>
<p>0 50 100 150 200 250 300 350 400 450</p>
<p>Number of tasks</p>
<p>Sequential</p>
<p>List Scheduling</p>
			<figure>
				<head>Figure 6</head>
				<figDesc>Performance ratio for the simulation on 200 processors, cirne model parallel tasks</figDesc>
			</figure>
<p>if we remark that, for a weakly parallel task, there is only one or two intervals in which it can be scheduled without degrading its performance. So the scheduling algorithm is more constrained when the tasks are not parallel. The SAF algorithm perform quite well on simple cases. It appears on complex cases that our approach is required to keep a good performance on the minsum criterion. Thus our algorithms should be preferred in actual applications as its performance ratio for minsum is insensitive to jobs behavior and its performance ratio for the makespan is not far from alternatives. Finally, Figure 7 shows that the execution time of our scheduling algorithm is low (less than 2 seconds for the largest instances), as expected.</p>
			<figure>
				<head>Figure 7</head>
				<figDesc>Execution time of the algorithm</figDesc>
			</figure>
<p>In this paper we presented a new algorithm for scheduling a set of independent jobs on a cluster. The main feature is to optimize two criteria simultaneously. The experiments show that in average the performance ratio is very good, and the algorithm is fast enough for practical use. The algorithm has been assessed by comparing the minsum performance to a new lower bound based on the relaxation of an ILP, and comparing the makespan performance to the best known approximation. Actual results are not available at the moment , but we are currently implementing this algorithm on a full-scale platform (Icluster2). Several technical problems still have to be solved for an even more efficient practical solution, namely the reservation of nodes which reduces the size of the cluster and the mix of different types of jobs (moldable jobs, rigid jobs, and divisible load jobs).</p>
			</div>
			<div n="5">
			        <head>CONCLUDING REMARKS</head>
<p>In this paper we presented a new algorithm for scheduling a set of independent jobs on a cluster. The main feature is to optimize two criteria simultaneously. The experiments show that in average the performance ratio is very good, and the algorithm is fast enough for practical use. The algorithm has been assessed by comparing the minsum performance to a new lower bound based on the relaxation of an ILP, and comparing the makespan performance to the best known approximation. Actual results are not available at the moment, but we are currently implementing this algorithm on a full-scale platform (Icluster2). </p>
<p>Several technical problems still have to be solved for an even more efficient practical solution, namely the reservation of nodes which reduces the size of the cluster and the mix of different types of jobs (moldable jobs, rigid jobs, and divisible load jobs).</p>
			</div>
			<div n="6">
				<head>REFERENCES</head>
			</div>
		</body>
		<back>
			<div type="references">
<listBibl>
<biblStruct xml:lang="en"  xml:id="b0">
	<monogr>
		<title level="m" type="main">The top500 organization website</title>
		<imprint>
			<biblScope type="pp">500</biblScope>
		</imprint>
	</monogr>
</biblStruct>
<biblStruct xml:lang="en"  xml:id="b1">
	<analytic>
		<title level="a" type="main">Scheduling to minimize the average completion time of dedicated tasks</title>
		<author>
			<persName>
				<forename>F.</forename>
				<surname>Afrati</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename>E.</forename>
				<surname>Bampis</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename>A. V.</forename>
				<surname>Fishkin</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename>K.</forename>
				<surname>Jansen</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename>C.</forename>
				<surname>Kenyon</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Lecture Notes in Computer Science</title>
		<imprint>
			<biblScope type="vol">vol</biblScope>
			<date>1974</date>
		</imprint>
	</monogr>
</biblStruct>
<biblStruct xml:lang="en"  xml:id="b2">
	<analytic>
		<title level="a" type="main">The MOSIX multicomputer operating system for high performance cluster computing</title>
		<author>
			<persName>
				<forename>A.</forename>
				<surname>Barak</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename>O.</forename>
				<surname>La&apos;adan</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Future Generation Computer Systems</title>
		<imprint>
			<biblScope type="vol">13</biblScope>
			<biblScope type="issue">4</biblScope>
			<biblScope type="fpage">361</biblScope>
			<biblScope type="lpage">372</biblScope>
			<date>1998</date>
		</imprint>
	</monogr>
</biblStruct>
<biblStruct xml:lang="en"  xml:id="b3">
	<analytic>
		<title level="a" type="main">The AppLeS parameter sweep template: User-level middleware for the grid</title>
		<author>
			<persName>
				<forename>H.</forename>
				<surname>Casanova</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename>G.</forename>
				<surname>Obertelli</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename>F.</forename>
				<surname>Berman</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename>R.</forename>
				<surname>Wolski</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">In Proceedings of SuperComputing&apos;2000</title>
		<meeting>SuperComputing&apos;2000</meeting>
		<imprint>
			<date>2000</date>
		</imprint>
	</monogr>
</biblStruct>
<biblStruct xml:lang="en"  xml:id="b4">
	<analytic>
		<title level="a" type="main">A model for moldable supercomputer jobs</title>
		<author>
			<persName>
				<forename>W.</forename>
				<surname>Cirne</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename>F.</forename>
				<surname>Berman</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">In 15th Intl. Parallel &amp; Distributed Processing Symp</title>
		<imprint>
			<date>2001</date>
		</imprint>
	</monogr>
</biblStruct>
<biblStruct xml:lang="en"  xml:id="b5">
	<monogr>
		<title level="m" type="main">Parallel Computer Architecture: A Hardware/Software Approach</title>
		<author>
			<persName>
				<forename>D. E.</forename>
				<surname>Culler</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename>J. P.</forename>
				<surname>Singh</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename>A.</forename>
				<surname>Gupta</surname>
			</persName>
		</author>
		<imprint>
			<date>1999</date>
			<publisher>Morgan Kaufmann Publishers, inc</publisher>
			<pubPlace>San Francisco, CA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>
<biblStruct xml:lang="en"  xml:id="b6">
	<monogr>
		<title level="m" type="main">Handbook of Scheduling, chapter Scheduling Parallel Tasks-Approximation Algorithms</title>
		<author>
			<persName>
				<forename>P-F.</forename>
				<surname>Dutot</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename>G.</forename>
				<surname>Mouni&#233;</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename>D.</forename>
				<surname>Trystram</surname>
			</persName>
		</author>
		<imprint>
			<date>2004</date>
			<publisher>CRC Press</publisher>
		</imprint>
	</monogr>
</biblStruct>
<biblStruct xml:lang="en"  xml:id="b7">
	<analytic>
		<title level="a" type="main">Scheduling parallel jobs on clusters</title>
		<author>
			<persName>
				<forename>D. G.</forename>
				<surname>Feitelson</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">High Performance Cluster Computing</title>
		<editor>R. Buyya</editor>
		<imprint>
			<publisher>Prentice Hall</publisher>
			<date>1999</date>
			<biblScope type="fpage">519</biblScope>
			<biblScope type="lpage">533</biblScope>
		</imprint>
	</monogr>
	<note>Chap. 21</note>
</biblStruct>
<biblStruct xml:lang="en"  xml:id="b8">
	<analytic>
		<title level="a" type="main">Parallel job scheduling: Issues and approaches</title>
		<author>
			<persName>
				<forename>D. G.</forename>
				<surname>Feitelson</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename>L.</forename>
				<surname>Rudolph</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Lecture Notes in Computer Science</title>
		<imprint>
			<biblScope type="vol">0</biblScope>
			<biblScope type="issue">949</biblScope>
			<biblScope type="fpage">1</biblScope>
			<biblScope type="lpage">18</biblScope>
			<date>1995</date>
		</imprint>
	</monogr>
</biblStruct>
<biblStruct xml:lang="en"  xml:id="b9">
	<monogr>
		<title level="m" type="main">The grid: blueprint for a new computing infrastructure</title>
		<author>
			<persName>
				<forename>I.</forename>
				<surname>Foster</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename>C.</forename>
				<surname>Kesselman</surname>
			</persName>
		</author>
		<imprint>
			<date>1999</date>
			<publisher>Morgan Kaufmann Publishers Inc</publisher>
		</imprint>
	</monogr>
</biblStruct>
<biblStruct xml:lang="en"  xml:id="b10">
	<analytic>
		<title level="a" type="main">Bounds on multiprocessor scheduling with resource constraints</title>
		<author>
			<persName>
				<forename>M. R.</forename>
				<surname>Garey</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename>R. L.</forename>
				<surname>Graham</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM Journal on Computing</title>
		<imprint>
			<biblScope type="vol">4</biblScope>
			<biblScope type="fpage">187</biblScope>
			<biblScope type="lpage">200</biblScope>
			<date>1975</date>
		</imprint>
	</monogr>
</biblStruct>
<biblStruct xml:lang="en"  xml:id="b11">
	<analytic>
		<title level="a" type="main">Scheduling to minimize average completion time: Off-line and on-line approximation algorithms</title>
		<author>
			<persName>
				<forename>L. A.</forename>
				<surname>Hall</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename>A. S.</forename>
				<surname>Schulz</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename>D. B.</forename>
				<surname>Shmoys</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename>J.</forename>
				<surname>Wein</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mathematics of Operations Research</title>
		<imprint>
			<biblScope type="vol">22</biblScope>
			<biblScope type="fpage">513</biblScope>
			<biblScope type="lpage">544</biblScope>
			<date>1997</date>
		</imprint>
	</monogr>
</biblStruct>
<biblStruct xml:lang="en"  xml:id="b12">
	<analytic>
		<title level="a" type="main">Job scheduling under the portable batch system</title>
		<author>
			<persName>
				<forename>R. L.</forename>
				<surname>Henderson</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Scheduling Strategies for Parallel Processing</title>
		<editor>D. G. Feitelson</editor>
		<editor>L. Rudolph</editor>
		<imprint>
			<date>1995</date>
			<biblScope type="fpage">279</biblScope>
			<biblScope type="lpage">294</biblScope>
		</imprint>
	</monogr>
</biblStruct>
<biblStruct xml:lang="en"  xml:id="b13">
	<analytic>
		<title level="a" type="main">Core algorithms of the maui schedule</title>
		<author>
			<persName>
				<forename>D.</forename>
				<surname>Jackson</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename>Q.</forename>
				<surname>Snell</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename>M. J.</forename>
				<surname>Clement</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Scheduling Strategies for Parallel Processing</title>
		<editor>D. G. Feitelson</editor>
		<editor>L. Rudolph</editor>
		<imprint>
			<date>2001</date>
			<biblScope type="fpage">87</biblScope>
			<biblScope type="lpage">102</biblScope>
		</imprint>
	</monogr>
</biblStruct>
<biblStruct xml:lang="en"  xml:id="b14">
	<monogr>
		<title level="m" type="main">The art of computer systems performance analysis</title>
		<author>
			<persName>
				<forename>R.</forename>
				<surname>Jain</surname>
			</persName>
		</author>
		<imprint>
			<date>1991</date>
			<publisher>John Wiley</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>
<biblStruct xml:lang="en"  xml:id="b15">
	<analytic>
		<title level="a" type="main">Condor : A hunter of idle workstations</title>
		<author>
			<persName>
				<forename>M. J.</forename>
				<surname>Litzkow</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename>M.</forename>
				<surname>Livny</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename>M. W.</forename>
				<surname>Mutka</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">In 8th International Conference on Distributed Computing Systems (ICDCS &apos;88</title>
		<meeting><address>Washington, D.C., USA</address></meeting>
		<imprint>
			<publisher>IEEE Computer Society Press</publisher>
			<date>1988</date>
			<biblScope type="fpage">104</biblScope>
			<biblScope type="lpage">111</biblScope>
		</imprint>
	</monogr>
</biblStruct>
<biblStruct xml:lang="en"  xml:id="b16">
	<analytic>
		<title level="a" type="main">Efficient approximation algorithms for scheduling malleable tasks</title>
		<author>
			<persName>
				<forename>G.</forename>
				<surname>Mouni&#233;</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename>C.</forename>
				<surname>Rapine</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename>D.</forename>
				<surname>Trystram</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">In Eleventh ACM Symposium on Parallel Algorithms and Architectures (SPAA&apos;99</title>
		<meeting><address>juin</address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date>1999</date>
			<biblScope type="fpage">23</biblScope>
			<biblScope type="lpage">32</biblScope>
		</imprint>
	</monogr>
</biblStruct>
<biblStruct xml:lang="en"  xml:id="b17">
	<analytic>
		<title level="a" type="main">A synthetic workload generator for cluster computing</title>
		<author>
			<persName>
				<forename>E.</forename>
				<surname>Romagnoli</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename>Y.</forename>
				<surname>Denneulin</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename>D.</forename>
				<surname>Trystram</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">In 3rd International Workshop on Performance Modeling, Evaluation, and Optimization of Parallel and Distributed Systems (PMEO-PDS&apos;2004) in conjunction with IPDPS&apos;04</title>
		<meeting><address>Santa Fe, New Mexico</address></meeting>
		<imprint>
			<date>2004</date>
		</imprint>
	</monogr>
</biblStruct>
<biblStruct xml:lang="en"  xml:id="b18">
	<analytic>
		<title level="a" type="main">Smart SMART bounds for weighted response time scheduling</title>
		<author>
			<persName>
				<forename>U.</forename>
				<surname>Schwiegelshohn</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename>W.</forename>
				<surname>Ludwig</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename>J.</forename>
				<surname>Wolf</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename>J.</forename>
				<surname>Turek</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename>P.</forename>
				<surname>Yu</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM Journal on Computing</title>
		<imprint>
			<biblScope type="vol">28</biblScope>
			<date>1998</date>
		</imprint>
	</monogr>
</biblStruct>
<biblStruct xml:lang="en"  xml:id="b19">
	<analytic>
		<title level="a" type="main">Multiresource malleable task scheduling to minimize response time</title>
		<author>
			<persName>
				<forename>H.</forename>
				<surname>Shachnai</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename>J.</forename>
				<surname>Turek</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Processing Letters</title>
		<imprint>
			<biblScope type="vol">70</biblScope>
			<biblScope type="fpage">47</biblScope>
			<biblScope type="lpage">52</biblScope>
			<date>1999</date>
		</imprint>
	</monogr>
</biblStruct>
<biblStruct xml:lang="en"  xml:id="b20">
	<analytic>
		<title level="a" type="main">Scheduling parallel machine on-line</title>
		<author>
			<persName>
				<forename>D.</forename>
				<surname>Shmoys</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename>J.</forename>
				<surname>Wein</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename>D.</forename>
				<surname>Williamson</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM Journal on Computing</title>
		<imprint>
			<biblScope type="vol">24</biblScope>
			<biblScope type="issue">6</biblScope>
			<biblScope type="fpage">1313</biblScope>
			<biblScope type="lpage">1331</biblScope>
			<date>1995</date>
		</imprint>
	</monogr>
</biblStruct>
</listBibl>
			</div>
		</back>
	</text>
</TEI>
